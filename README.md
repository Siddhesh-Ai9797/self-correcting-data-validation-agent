ğŸ¤– Self-Correcting Data Validation Agent
Schema-Enforced, No-Hallucination, Agentic Data Extraction Pipeline
A production-style Agentic AI system that converts unstructured employee data into schema-perfect JSON using:
LangGraph (state orchestration)
Pydantic v2 (strict schema validation)
OpenAI Structured Extraction
Deterministic Pandas Execution
Streamlit UI
Designed to demonstrate safe LLM integration with strict validation and zero hallucinated required fields.
ğŸ§  Problem
Large Language Models are powerful at extracting structure from messy text â€”
but they:
Hallucinate missing required fields
Produce schema-invalid JSON
Fabricate IDs
Output inconsistent formats
This project solves that by enforcing:
âœ” Strict schema validation
âœ” Autonomous correction retries
âœ” Deterministic execution
âœ” Explicit rejection handling
âœ” No fabricated required fields
ğŸ— System Architecture
Messy Text Input
â†’ LLM Extraction
â†’ Pydantic Schema Validation
â†’ (If Invalid) Self-Correction Loop
â†’ Final Schema-Valid Output
If required fields are missing (e.g., user_id), records are rejected â€” not hallucinated.
ğŸ” Agentic State Machine (LangGraph)
State:
raw_text
last_json_text
attempt
max_attempts
validation_error
result
log
Flow:
extract â†’ validate
If fail â†’ correct â†’ validate â†’ repeat
Else â†’ finalize
The retry loop is controlled and bounded.
ğŸ“¦ Core Features
1ï¸âƒ£ Structured Extraction
LLM converts messy input into strict JSON format:
{
  "employees": [
    {
      "user_id": int,
      "name": string,
      "age": int|null,
      "email": string|null,
      "salary": number|null,
      "join_date": YYYY-MM-DD|null,
      "department": enum,
      "performance_score": 0â€“10|null,
      "location": string|null,
      "job_title": string|null
    }
  ]
}
Normalization rules include:
Word numbers â†’ integers
Salary cleaning
Department mapping
ISO date formatting
Out-of-range correction
2ï¸âƒ£ Schema Enforcement (Pydantic v2)
All extracted data must pass:
Required fields enforced
Numeric bounds checked
Enum constraints enforced
Date type validation
No NaN allowed
No empty strings for missing values
If validation fails â†’ correction step triggered.
3ï¸âƒ£ Self-Correction Loop
When validation fails:
The model receives:
Previous JSON
Validation error message
It must correct the structure
No records may be silently dropped
Retry limit enforced
Zero hallucinated user_id.
4ï¸âƒ£ No-Hallucination Guarantee
If required fields are missing:
{
  "employees": [],
  "rejected": [
    {
      "raw_record": "...",
      "reasons": ["missing user_id"]
    }
  ]
}
The system never fabricates identifiers.
5ï¸âƒ£ Deterministic Query Engine
For dataset questions:
LLM generates structured query plan
Pandas executes filtering/aggregation
LLM only summarizes computed results
This prevents synthetic answer fabrication.
ğŸ§ª Stress Testing
Includes automated agent suite:
python -m src.eval.run_agent_suite
Results:
15/15 cases passed
100% schema-valid outputs
Correct rejection behavior
Avg attempts: 1.0
No hallucinated required fields
Edge cases tested:
Word numbers
Missing fields
Conflicting values
Garbage text
Extreme noise
Multiple records
Unstructured paragraphs
ğŸ–¥ Interface (Streamlit)
Run:
streamlit run app.py
UI includes:
ğŸ“„ Data Cleaning Tab
ğŸ’¬ Deterministic Query Tab
ğŸ§  Self-Correcting Agent Tab
Agent tab provides:
Correction Log
Retry Count
Before / After view
Valid vs Rejected records
JSON download
ğŸ“‚ Project Structure
industry_ready_data_agent/

app.py
requirements.txt
README.md

src/
    agent/
        graph.py
        schemas.py
    core/
        cleaning.py
        query.py
    eval/
        run_agent_suite.py

test_inputs/
employee_dataset_50rows.csv
ğŸš€ Installation
Clone repository:
git clone git@github.com:Siddhesh-Ai9797/self-correcting-data-validation-agent.git
cd self-correcting-data-validation-agent
Create environment:
python -m venv .venv
source .venv/bin/activate
Install dependencies:
pip install -r requirements.txt
Set API key:
export OPENAI_API_KEY="your_key_here"
Run:
streamlit run app.py
ğŸ” Design Principles
Fail closed, not open
Deterministic where possible
Explicit rejection > silent correction
Structured retries only
Bounded correction loop
JSON-safe serialization
ğŸ“ˆ Production Readiness
Current system demonstrates:
âœ” Agent orchestration
âœ” Schema enforcement
âœ” Deterministic execution layer
âœ” Retry loop logic
âœ” Controlled LLM behavior
Future extensions:
FastAPI backend
Persistent storage
Docker containerization
Structured logging
Role-based validation
Deployment to AWS
ğŸ¯ Why This Project Matters
This is not just a demo app.
It demonstrates how to build:
Safe LLM pipelines
Controlled agent systems
Validation-first AI architecture
Production-oriented AI engineering
Most LLM apps hallucinate.
This one enforces correctness.
ğŸ‘¨â€ğŸ’» Author
Siddhesh Patil
M.S. Artificial Intelligence
DePaul University
